{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ MODEL TRAINING \n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "MODEL TRAINING - Soccer Match Predictor\n",
    "Goal: Train ML models and BEAT 72% ACCURACY!\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Style\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"ü§ñ MODEL TRAINING \")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading processed data with features...\n",
      "\n",
      "['date', 'home_team', 'away_team', 'home_score', 'away_score', 'matchday', 'result', 'home_form', 'away_form', 'form_diff', 'home_goals_scored_avg', 'home_goals_conceded_avg', 'away_goals_scored_avg', 'away_goals_conceded_avg', 'offensive_strength_diff', 'defensive_strength_diff', 'home_team_value', 'away_team_value', 'value_diff', 'home_win_rate', 'away_win_rate', 'win_rate_diff', 'home_points_match', 'away_points_match', 'home_points_cum', 'away_points_cum', 'home_goal_diff_match', 'away_goal_diff_match', 'home_goal_diff_cum', 'away_goal_diff_cum', 'home_recent_points5', 'away_recent_points5', 'rest_days_home', 'rest_days_away', 'home_big6', 'away_big6']\n",
      "‚úÖ Loaded 760 matches\n",
      "üìä Shape: (760, 36)\n",
      "\n",
      "üëÄ Columns:\n",
      "['date', 'home_team', 'away_team', 'home_score', 'away_score', 'matchday', 'result', 'home_form', 'away_form', 'form_diff', 'home_goals_scored_avg', 'home_goals_conceded_avg', 'away_goals_scored_avg', 'away_goals_conceded_avg', 'offensive_strength_diff', 'defensive_strength_diff', 'home_team_value', 'away_team_value', 'value_diff', 'home_win_rate', 'away_win_rate', 'win_rate_diff', 'home_points_match', 'away_points_match', 'home_points_cum', 'away_points_cum', 'home_goal_diff_match', 'away_goal_diff_match', 'home_goal_diff_cum', 'away_goal_diff_cum', 'home_recent_points5', 'away_recent_points5', 'rest_days_home', 'rest_days_away', 'home_big6', 'away_big6']\n",
      "\n",
      "üéØ Target distribution:\n",
      "result\n",
      "H    330\n",
      "A    255\n",
      "D    175\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Percentages:\n",
      "result\n",
      "H    43.42\n",
      "A    33.55\n",
      "D    23.03\n",
      "Name: count, dtype: float64\n",
      "\n",
      "üìã Sample data:\n",
      "                        date                  home_team             away_team  \\\n",
      "0  2023-08-11 19:00:00+00:00                 Burnley FC    Manchester City FC   \n",
      "1  2023-08-12 12:00:00+00:00                 Arsenal FC  Nottingham Forest FC   \n",
      "2  2023-08-12 14:00:00+00:00            AFC Bournemouth    West Ham United FC   \n",
      "3  2023-08-12 14:00:00+00:00  Brighton & Hove Albion FC         Luton Town FC   \n",
      "4  2023-08-12 14:00:00+00:00                 Everton FC             Fulham FC   \n",
      "\n",
      "   home_score  away_score  matchday result  home_form  away_form  form_diff  \\\n",
      "0           0           3         1      A          0          0          0   \n",
      "1           2           1         1      H          0          0          0   \n",
      "2           1           1         1      D          0          0          0   \n",
      "3           4           1         1      H          0          0          0   \n",
      "4           0           1         1      A          0          0          0   \n",
      "\n",
      "   ...  home_goal_diff_match  away_goal_diff_match  home_goal_diff_cum  \\\n",
      "0  ...                    -3                     3                 0.0   \n",
      "1  ...                     1                    -1                -3.0   \n",
      "2  ...                     0                     0                 1.0   \n",
      "3  ...                     3                    -3                 0.0   \n",
      "4  ...                    -1                     1                 3.0   \n",
      "\n",
      "   away_goal_diff_cum  home_recent_points5  away_recent_points5  \\\n",
      "0                 0.0                  8.0                  0.0   \n",
      "1                 3.0                  7.0                  7.0   \n",
      "2                -1.0                  NaN                  1.0   \n",
      "3                 0.0                  7.0                  6.0   \n",
      "4                -3.0                 11.0                  9.0   \n",
      "\n",
      "   rest_days_home  rest_days_away  home_big6  away_big6  \n",
      "0             7.0             7.0          0          1  \n",
      "1             7.0             7.0          1          0  \n",
      "2             7.0             7.0          0          0  \n",
      "3             7.0             7.0          0          0  \n",
      "4             7.0             7.0          0          0  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# LOAD PROCESSED DATA\n",
    "# ============================================\n",
    "\n",
    "print(\"üìÇ Loading processed data with features...\\n\")\n",
    "\n",
    "df = pd.read_csv('../data/processed/matches_with_features.csv')\n",
    "print(df.columns.tolist())\n",
    "\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(df)} matches\")\n",
    "print(f\"üìä Shape: {df.shape}\")\n",
    "print(f\"\\nüëÄ Columns:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(f\"\\nüéØ Target distribution:\")\n",
    "print(df['result'].value_counts())\n",
    "print(f\"\\nPercentages:\")\n",
    "print((df['result'].value_counts() / len(df) * 100).round(2))\n",
    "\n",
    "# Quick peek\n",
    "print(f\"\\nüìã Sample data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Preparing data with ALL FEATURES...\n",
      "\n",
      "üìä Using 25 features:\n",
      "  1. home_form\n",
      "  2. away_form\n",
      "  3. form_diff\n",
      "  4. home_goals_scored_avg\n",
      "  5. home_goals_conceded_avg\n",
      "  6. away_goals_scored_avg\n",
      "  7. away_goals_conceded_avg\n",
      "  8. offensive_strength_diff\n",
      "  9. defensive_strength_diff\n",
      "  10. home_team_value\n",
      "  11. away_team_value\n",
      "  12. value_diff\n",
      "  13. home_win_rate\n",
      "  14. away_win_rate\n",
      "  15. win_rate_diff\n",
      "  16. home_points_cum\n",
      "  17. away_points_cum\n",
      "  18. home_goal_diff_cum\n",
      "  19. away_goal_diff_cum\n",
      "  20. home_recent_points5\n",
      "  21. away_recent_points5\n",
      "  22. rest_days_home\n",
      "  23. rest_days_away\n",
      "  24. home_big6\n",
      "  25. away_big6\n",
      "\n",
      "üîç Missing values: 2 total\n",
      "‚úÖ After fillna: 0 missing\n",
      "\n",
      "‚úÖ Features (X): (760, 25)\n",
      "‚úÖ Target (y): (760,)\n",
      "\n",
      "üî§ Target encoding:\n",
      "  A ‚Üí 0\n",
      "  D ‚Üí 1\n",
      "  H ‚Üí 2\n",
      "\n",
      "üì¶ Train set: 608 matches (80.0%)\n",
      "üì¶ Test set: 152 matches (20.0%)\n",
      "\n",
      "‚úÖ DATA READY FOR TRAINING!\n",
      "üéØ Baseline to beat: 43.42%\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# DATA PREPARATION FOR ML - ALL FEATURES\n",
    "# ============================================\n",
    "\n",
    "print(\"üîß Preparing data with ALL FEATURES...\\n\")\n",
    "\n",
    "# 1. D√©finir ce qu'on EXCLUT\n",
    "metadata_cols = [\n",
    "    'date', 'home_team', 'away_team',\n",
    "    'home_score', 'away_score', 'matchday', 'result'\n",
    "]\n",
    "\n",
    "# Features d√©riv√©es du score (data leakage!)\n",
    "score_derived = [\n",
    "    'home_points_match', 'away_points_match',\n",
    "    'home_goal_diff_match', 'away_goal_diff_match'\n",
    "]\n",
    "\n",
    "# 2. Toutes les autres colonnes = features\n",
    "exclude_cols = metadata_cols + score_derived\n",
    "feature_columns = [c for c in df.columns if c not in exclude_cols]\n",
    "\n",
    "print(f\"üìä Using {len(feature_columns)} features:\")\n",
    "for i, f in enumerate(feature_columns, 1):\n",
    "    print(f\"  {i}. {f}\")\n",
    "\n",
    "# 3. Pr√©parer X et y\n",
    "X = df[feature_columns].copy()\n",
    "y = df['result'].copy()\n",
    "\n",
    "# 4. G√©rer les NaN\n",
    "print(f\"\\nüîç Missing values: {X.isna().sum().sum()} total\")\n",
    "X = X.fillna(0)\n",
    "print(f\"‚úÖ After fillna: {X.isna().sum().sum()} missing\")\n",
    "\n",
    "print(f\"\\n‚úÖ Features (X): {X.shape}\")\n",
    "print(f\"‚úÖ Target (y): {y.shape}\")\n",
    "\n",
    "# 5. Encoder le target (H/A/D ‚Üí 0/1/2)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(f\"\\nüî§ Target encoding:\")\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    print(f\"  {label} ‚Üí {i}\")\n",
    "\n",
    "# 6. Train/Test split (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"\\nüì¶ Train set: {X_train.shape[0]} matches ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"üì¶ Test set: {X_test.shape[0]} matches ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n‚úÖ DATA READY FOR TRAINING!\")\n",
    "print(f\"üéØ Baseline to beat: {max(y.value_counts())/len(y)*100:.2f}%\")\n",
    "\n",
    "# 7. Sauvegarder labels pour plus tard\n",
    "labels = label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Training Model 1: Logistic Regression\n",
      "============================================================\n",
      "This is our baseline ML model - simplest algorithm\n",
      "\n",
      "üìä RESULTS:\n",
      "  Training Accuracy: 53.45%\n",
      "  Test Accuracy: 46.05%\n",
      "\n",
      "üéØ vs Baseline (43.42%): +2.63 points\n",
      "\n",
      "‚ö†Ô∏è  Needs improvement, but better than baseline!\n",
      "\n",
      "üìã CONFUSION MATRIX:\n",
      "\n",
      "Actual ‚Üí\n",
      "Predicted ‚Üì\n",
      "    A   D   H\n",
      "A  29  12  10\n",
      "D  14   9  12\n",
      "H  21  13  32\n",
      "\n",
      "üìä DETAILED CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.45      0.57      0.50        51\n",
      "           D       0.26      0.26      0.26        35\n",
      "           H       0.59      0.48      0.53        66\n",
      "\n",
      "    accuracy                           0.46       152\n",
      "   macro avg       0.44      0.44      0.43       152\n",
      "weighted avg       0.47      0.46      0.46       152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# MODEL 1: LOGISTIC REGRESSION (BASELINE ML)\n",
    "# ============================================\n",
    "\n",
    "print(\"ü§ñ Training Model 1: Logistic Regression\")\n",
    "print(\"=\"*60)\n",
    "print(\"This is our baseline ML model - simplest algorithm\\n\")\n",
    "\n",
    "# Train\n",
    "lr_model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        class_weight='balanced',\n",
    "        multi_class='multinomial'\n",
    "    ))\n",
    "])\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_train = lr_model.predict(X_train)\n",
    "y_pred_test = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"üìä RESULTS:\")\n",
    "print(f\"  Training Accuracy: {train_acc*100:.2f}%\")\n",
    "print(f\"  Test Accuracy: {test_acc*100:.2f}%\")\n",
    "print(f\"\\nüéØ vs Baseline (43.42%): {test_acc*100 - 43.42:+.2f} points\")\n",
    "\n",
    "if test_acc > 0.7:\n",
    "    print(f\"\\nüî•üî•üî• HOLY SHIT! WE BEAT 70%!! üî•üî•üî•\")\n",
    "elif test_acc > 0.6:\n",
    "    print(f\"\\nüî• NICE! Above 60%! We're getting there!\")\n",
    "elif test_acc > 0.5:\n",
    "    print(f\"\\n‚úÖ Good! Better than random (50%)\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Needs improvement, but better than baseline!\")\n",
    "\n",
    "# Confusion Matrix\n",
    "print(f\"\\nüìã CONFUSION MATRIX:\")\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "labels = label_encoder.classes_\n",
    "\n",
    "# Pretty print\n",
    "print(\"\\nActual ‚Üí\")\n",
    "print(\"Predicted ‚Üì\")\n",
    "cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "print(cm_df)\n",
    "\n",
    "# Detailed report\n",
    "print(f\"\\nüìä DETAILED CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå≥ Training Model 2: Random Forest\n",
      "============================================================\n",
      "More powerful than Logistic Regression - should handle\n",
      "the class imbalance better!\n",
      "\n",
      "üìä RESULTS:\n",
      "  Training Accuracy: 95.72%\n",
      "  Test Accuracy: 51.32%\n",
      "\n",
      "üéØ vs Baseline (43.42%): +7.90 points\n",
      "üÜö vs Logistic Regression: +5.26 points\n",
      "\n",
      "üìà Better, but still work to do!\n",
      "\n",
      "üìã CONFUSION MATRIX:\n",
      "    A  D   H\n",
      "A  33  6  12\n",
      "D  14  6  15\n",
      "H  18  9  39\n",
      "\n",
      "üìä DETAILED CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.51      0.65      0.57        51\n",
      "           D       0.29      0.17      0.21        35\n",
      "           H       0.59      0.59      0.59        66\n",
      "\n",
      "    accuracy                           0.51       152\n",
      "   macro avg       0.46      0.47      0.46       152\n",
      "weighted avg       0.49      0.51      0.50       152\n",
      "\n",
      "\n",
      "üéØ FEATURE IMPORTANCE:\n",
      "                feature  importance\n",
      "             value_diff    0.110624\n",
      "        home_team_value    0.063178\n",
      "          win_rate_diff    0.053534\n",
      "        home_points_cum    0.049033\n",
      "     home_goal_diff_cum    0.048136\n",
      "        away_team_value    0.046268\n",
      "        away_points_cum    0.046000\n",
      "          home_win_rate    0.045134\n",
      "              form_diff    0.044725\n",
      "         rest_days_home    0.043615\n",
      "home_goals_conceded_avg    0.040390\n",
      "     away_goal_diff_cum    0.038546\n",
      "offensive_strength_diff    0.038244\n",
      "         rest_days_away    0.036895\n",
      "defensive_strength_diff    0.036891\n",
      "              home_form    0.035085\n",
      "away_goals_conceded_avg    0.034005\n",
      "    home_recent_points5    0.030753\n",
      "          away_win_rate    0.030245\n",
      "  home_goals_scored_avg    0.030229\n",
      "              away_form    0.027632\n",
      "    away_recent_points5    0.027575\n",
      "  away_goals_scored_avg    0.027432\n",
      "              home_big6    0.009123\n",
      "              away_big6    0.006709\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# MODEL 2: RANDOM FOREST (PLUS PUISSANT!)\n",
    "# ============================================\n",
    "\n",
    "print(\"üå≥ Training Model 2: Random Forest\")\n",
    "print(\"=\"*60)\n",
    "print(\"More powerful than Logistic Regression - should handle\")\n",
    "print(\"the class imbalance better!\\n\")\n",
    "\n",
    "# Train avec class_weight pour g√©rer le d√©s√©quilibre\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=400,        # plus d'arbres = plus stable\n",
    "    max_depth=8,             # moins profond = moins d'overfit\n",
    "    min_samples_leaf=2,      # chaque feuille a au moins 4 matchs\n",
    "    max_features='sqrt',     # classique en RF\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_train_rf = rf_model.predict(X_train)\n",
    "y_pred_test_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "train_acc_rf = accuracy_score(y_train, y_pred_train_rf)\n",
    "test_acc_rf = accuracy_score(y_test, y_pred_test_rf)\n",
    "\n",
    "print(f\"üìä RESULTS:\")\n",
    "print(f\"  Training Accuracy: {train_acc_rf*100:.2f}%\")\n",
    "print(f\"  Test Accuracy: {test_acc_rf*100:.2f}%\")\n",
    "print(f\"\\nüéØ vs Baseline (43.42%): {test_acc_rf*100 - 43.42:+.2f} points\")\n",
    "print(f\"üÜö vs Logistic Regression: {test_acc_rf*100 - test_acc*100:+.2f} points\")\n",
    "\n",
    "if test_acc_rf > 0.72:\n",
    "    print(f\"\\nüî•üî•üî• WE DID IT!! 72%+ ACHIEVED!! üî•üî•üî•\")\n",
    "elif test_acc_rf > 0.65:\n",
    "    print(f\"\\nüî• GREAT! We're getting close to 72%!\")\n",
    "elif test_acc_rf > 0.6:\n",
    "    print(f\"\\n‚úÖ Good improvement! Above 60%!\")\n",
    "else:\n",
    "    print(f\"\\nüìà Better, but still work to do!\")\n",
    "\n",
    "# Confusion Matrix\n",
    "print(f\"\\nüìã CONFUSION MATRIX:\")\n",
    "cm_rf = confusion_matrix(y_test, y_pred_test_rf)\n",
    "cm_rf_df = pd.DataFrame(cm_rf, index=labels, columns=labels)\n",
    "print(cm_rf_df)\n",
    "\n",
    "# Classification Report\n",
    "print(f\"\\nüìä DETAILED CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_test, y_pred_test_rf, target_names=labels))\n",
    "\n",
    "# Feature Importance\n",
    "print(f\"\\nüéØ FEATURE IMPORTANCE:\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèÖ Top Feature Importances (Random Forest):\n",
      "value_diff            0.110624\n",
      "home_team_value       0.063178\n",
      "win_rate_diff         0.053534\n",
      "home_points_cum       0.049033\n",
      "home_goal_diff_cum    0.048136\n",
      "away_team_value       0.046268\n",
      "away_points_cum       0.046000\n",
      "home_win_rate         0.045134\n",
      "form_diff             0.044725\n",
      "rest_days_home        0.043615\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # si c'est d√©j√† import√© en haut, c'est pas grave\n",
    "\n",
    "feature_importances = pd.Series(\n",
    "    rf_model.feature_importances_,\n",
    "    index=feature_columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nüèÖ Top Feature Importances (Random Forest):\")\n",
    "print(feature_importances.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî• Training Model 3: XGBoost (Balanced)\n",
      "============================================================\n",
      "Training with balanced hyperparameters...\n",
      "\n",
      "üìä RESULTS (XGBoost Balanced):\n",
      "  Training Accuracy: 89.14%\n",
      "  Test Accuracy:     53.29%\n",
      "  Overfit Gap:       35.86%\n",
      "\n",
      "üéØ vs Baseline (43.42%): +9.87 points\n",
      "üÜö vs Original XGB (53.29%): -0.00 points\n",
      "\n",
      "‚úÖ Close to original, similar performance\n",
      "\n",
      "üìã CONFUSION MATRIX:\n",
      "    A  D   H\n",
      "A  32  5  14\n",
      "D  14  4  17\n",
      "H  13  8  45\n",
      "\n",
      "üìä CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.54      0.63      0.58        51\n",
      "           D       0.24      0.11      0.15        35\n",
      "           H       0.59      0.68      0.63        66\n",
      "\n",
      "    accuracy                           0.53       152\n",
      "   macro avg       0.46      0.47      0.46       152\n",
      "weighted avg       0.49      0.53      0.51       152\n",
      "\n",
      "\n",
      "üéØ TOP 10 FEATURES:\n",
      "                feature  importance\n",
      "             value_diff    0.068478\n",
      "        home_team_value    0.055144\n",
      "              form_diff    0.054930\n",
      "              home_big6    0.049664\n",
      "          win_rate_diff    0.049496\n",
      "          home_win_rate    0.046917\n",
      "        away_team_value    0.041238\n",
      "              home_form    0.039291\n",
      "     home_goal_diff_cum    0.037142\n",
      "offensive_strength_diff    0.036878\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# MODEL 3: XGBOOST (BALANCED)\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüî• Training Model 3: XGBoost (Balanced)\")\n",
    "print(\"============================================================\")\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    num_class=len(np.unique(y_train)),\n",
    "    eval_metric='mlogloss',\n",
    "\n",
    "    # Sweet spot entre capacit√© et r√©gularisation\n",
    "    n_estimators=200,        # Keep original\n",
    "    learning_rate=0.08,      # Entre 0.05 et 0.1\n",
    "    max_depth=4,             # Un peu plus (3‚Üí4)\n",
    "\n",
    "    # R√©gularisation mod√©r√©e\n",
    "    min_child_weight=6,      # Entre 5 et 8\n",
    "    subsample=0.75,          # Entre 0.7 et 0.8\n",
    "    colsample_bytree=0.75,   # Entre 0.7 et 0.8\n",
    "    gamma=0.5,               # Mod√©r√© (pas 1.0)\n",
    "    reg_lambda=2.5,          # Entre 2 et 3\n",
    "    reg_alpha=1.2,           # Entre 1 et 1.5\n",
    "\n",
    "    tree_method='hist',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training with balanced hyperparameters...\")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred_xgb = xgb_model.predict(X_train)\n",
    "y_test_pred_xgb  = xgb_model.predict(X_test)\n",
    "\n",
    "train_acc_xgb = accuracy_score(y_train, y_train_pred_xgb) * 100\n",
    "test_acc_xgb  = accuracy_score(y_test, y_test_pred_xgb) * 100\n",
    "\n",
    "print(\"\\nüìä RESULTS (XGBoost Balanced):\")\n",
    "print(f\"  Training Accuracy: {train_acc_xgb:.2f}%\")\n",
    "print(f\"  Test Accuracy:     {test_acc_xgb:.2f}%\")\n",
    "print(f\"  Overfit Gap:       {train_acc_xgb - test_acc_xgb:.2f}%\")\n",
    "\n",
    "print(f\"\\nüéØ vs Baseline (43.42%): {test_acc_xgb - 43.42:+.2f} points\")\n",
    "print(f\"üÜö vs Original XGB (53.29%): {test_acc_xgb - 53.29:+.2f} points\")\n",
    "\n",
    "if test_acc_xgb > 53.29:\n",
    "    print(f\"\\nüî• IMPROVED! New best: {test_acc_xgb:.2f}%\")\n",
    "elif test_acc_xgb > 52.5:\n",
    "    print(f\"\\n‚úÖ Close to original, similar performance\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Original was better at 53.29%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "print(f\"\\nüìã CONFUSION MATRIX:\")\n",
    "cm_xgb = confusion_matrix(y_test, y_test_pred_xgb)\n",
    "cm_xgb_df = pd.DataFrame(cm_xgb, index=labels, columns=labels)\n",
    "print(cm_xgb_df)\n",
    "\n",
    "print(f\"\\nüìä CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_test, y_test_pred_xgb, target_names=labels))\n",
    "\n",
    "# Feature Importance\n",
    "print(f\"\\nüéØ TOP 10 FEATURES:\")\n",
    "feature_imp = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(10)\n",
    "print(feature_imp.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
